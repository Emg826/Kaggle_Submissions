# Machine Learning - Kaggle Submissions
Kaggle.com is a website that hosts machine learning data sets and many machine learning competitions. This repository is a collection of python notebooks detailing my submissions to various contests on the website. The notebooks are written such that they try to cover the entire process of model building: data cleaning, feature engineering, model building, model selection, and making predictions. 

## Competition Notebooks
+ identify_rare_decay_phenomenon.ipynb: try to identify τ → μμμ decay. The τ → μμμ decay is a type of decay that violates the law of conservation of energy; nevertheless, according to some theories it is still possible. Therefore, a Monte Carlo simulation based on such theories created instances of this decay and mixed them in with other instances where this decay did not happen. Essentially, this was a classification problem, but with a twist: there were 3 metrics to consider. The 3 metrics were the Kolmogorov-Smirnov value, the Cramer-von Mises value, and the weighted area under the receiver operating characteristic curve. The first 2 were used to ensure the classification model was not using the imperfections in the Monte Carlo simulation to make its classifications. The last one was to ensure that if the model registers a hit/decay then there is a high probabliity that the hit/decay is correct. The best result was achieved by averaging the predictions of a multilayer perceptron, support vector machine, random forerst, and logistic regressor. As of July 29, 2018, that model sits at **12th place out of 29 teams (top 42%)** with its **weighted AUROC curve of 0.980854**.

+ house_sale_price_predicting.ipynb: try to predict the sale price of houses in Ames, Iowa. A lot of feature engineering was required to due to the dimensionality of the data set: there were 79 variables. This involved binary, ordinal, and dummy encoding columns, replacing and imputing missing values, and adding some columns of my own by synthesizing information from other columns. A lasso regressor, linear regressor, random forest regressor, suppor vector regressor, and elastic net regressor were tested, but the best model ended up being a combination: the average of the random forest and the support vector regressors' predictions. Though it took some time to arrive at this averaging model, the benefit was substantial: it scored a root mean squared log error (the metric for the competition) of 0.13059. Previously, the best model was the random forest regressor which scored an RMSLE of 0.14447 and placed at 2272nd  place out of 4969 teams. The averaging model's RMSLE places it at **1556th place out of 4808 teams (top 33%)** as of July 29, 2018.

+ titanic_survivor_predictions.ipynb: try to predict who did and did not survive the Titanic. This required feature engineering, missing value imputation, and testing various algorithms for generalizablity. The top performing algorithm, the multilayer perceptron regressor (neural network), achieved 79.4% accuracy, which, as of July 29, 2018, puts the model at **1,897th place out of 10,380 people (top 19%)**. 


## Non-Competition Notebooks
+ concrete_strength_prediction.ipynb: try to predict the concrete compressive strength, which is how much pressure concrete can withstand. Compressive strength is measure in mega Pascals (MPa), and 1 MPa is about 145 psi according to Google. Trying to predict a continuous value meant that I used mean squared error (MSE) to evaluate different models. The baseline model, linear regression, had an MSE of about 120 while the best model, which split the data into 2 subsets and trained 2 models on those 2 subsets, had an MSE of about 23. This means that the average guesses were off by 11 MPa and 4.8 MPa, respectively. This was not a competition, so there is **no leaderboard placement to report.**
