{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trys to predict the sale price of houses in Ames, Iowa, given 79 explanatory variables. This is another kaggle data set/competition (found here: https://www.kaggle.com/c/house-prices-advanced-regression-techniques) with the goal of building a model with the lowest root mean squared logarithmic error. A root log squared error of 0 is the best possible, so minimizing it the goal. To accomplish this goal, a lot of feature engineering will be done so as to give the model more data with which to work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pandas.read_csv('train.csv')\n",
    "df_test = pandas.read_csv('test.csv')\n",
    "\n",
    "train_csv_ids = df_train['Id'].values.ravel()\n",
    "test_csv_ids = df_test['Id'].values.ravel()\n",
    "\n",
    "df = pandas.concat( [df_train, df_test], sort=True ).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num rows: 2919\n",
      "Num cols: 81\n"
     ]
    }
   ],
   "source": [
    "print('Num rows: {}'.format(df.shape[0]))\n",
    "print('Num cols: {}'.format(df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column \t Number of Empty Entries \t First 3 Entries\n",
      "1stFlrSF \t\t 0 \t\t [ 856 1262  920]\n",
      "2ndFlrSF \t\t 0 \t\t [854   0 866]\n",
      "3SsnPorch \t\t 0 \t\t [0 0 0]\n",
      "Alley \t\t 2721 \t\t [nan nan nan]\n",
      "BedroomAbvGr \t\t 0 \t\t [3 3 3]\n",
      "BldgType \t\t 0 \t\t ['1Fam' '1Fam' '1Fam']\n",
      "BsmtCond \t\t 82 \t\t ['TA' 'TA' 'TA']\n",
      "BsmtExposure \t\t 82 \t\t ['No' 'Gd' 'Mn']\n",
      "BsmtFinSF1 \t\t 1 \t\t [706. 978. 486.]\n",
      "BsmtFinSF2 \t\t 1 \t\t [0. 0. 0.]\n",
      "BsmtFinType1 \t\t 79 \t\t ['GLQ' 'ALQ' 'GLQ']\n",
      "BsmtFinType2 \t\t 80 \t\t ['Unf' 'Unf' 'Unf']\n",
      "BsmtFullBath \t\t 2 \t\t [1. 0. 1.]\n",
      "BsmtHalfBath \t\t 2 \t\t [0. 1. 0.]\n",
      "BsmtQual \t\t 81 \t\t ['Gd' 'Gd' 'Gd']\n",
      "BsmtUnfSF \t\t 1 \t\t [150. 284. 434.]\n",
      "CentralAir \t\t 0 \t\t ['Y' 'Y' 'Y']\n",
      "Condition1 \t\t 0 \t\t ['Norm' 'Feedr' 'Norm']\n",
      "Condition2 \t\t 0 \t\t ['Norm' 'Norm' 'Norm']\n",
      "Electrical \t\t 1 \t\t ['SBrkr' 'SBrkr' 'SBrkr']\n",
      "EnclosedPorch \t\t 0 \t\t [0 0 0]\n",
      "ExterCond \t\t 0 \t\t ['TA' 'TA' 'TA']\n",
      "ExterQual \t\t 0 \t\t ['Gd' 'TA' 'Gd']\n",
      "Exterior1st \t\t 1 \t\t ['VinylSd' 'MetalSd' 'VinylSd']\n",
      "Exterior2nd \t\t 1 \t\t ['VinylSd' 'MetalSd' 'VinylSd']\n",
      "Fence \t\t 2348 \t\t [nan nan nan]\n",
      "FireplaceQu \t\t 1420 \t\t [nan 'TA' 'TA']\n",
      "Fireplaces \t\t 0 \t\t [0 1 1]\n",
      "Foundation \t\t 0 \t\t ['PConc' 'CBlock' 'PConc']\n",
      "FullBath \t\t 0 \t\t [2 2 2]\n",
      "Functional \t\t 2 \t\t ['Typ' 'Typ' 'Typ']\n",
      "GarageArea \t\t 1 \t\t [548. 460. 608.]\n",
      "GarageCars \t\t 1 \t\t [2. 2. 2.]\n",
      "GarageCond \t\t 159 \t\t ['TA' 'TA' 'TA']\n",
      "GarageFinish \t\t 159 \t\t ['RFn' 'RFn' 'RFn']\n",
      "GarageQual \t\t 159 \t\t ['TA' 'TA' 'TA']\n",
      "GarageType \t\t 157 \t\t ['Attchd' 'Attchd' 'Attchd']\n",
      "GarageYrBlt \t\t 159 \t\t [2003. 1976. 2001.]\n",
      "GrLivArea \t\t 0 \t\t [1710 1262 1786]\n",
      "HalfBath \t\t 0 \t\t [1 0 1]\n",
      "Heating \t\t 0 \t\t ['GasA' 'GasA' 'GasA']\n",
      "HeatingQC \t\t 0 \t\t ['Ex' 'Ex' 'Ex']\n",
      "HouseStyle \t\t 0 \t\t ['2Story' '1Story' '2Story']\n",
      "Id \t\t 0 \t\t [1 2 3]\n",
      "KitchenAbvGr \t\t 0 \t\t [1 1 1]\n",
      "KitchenQual \t\t 1 \t\t ['Gd' 'TA' 'Gd']\n",
      "LandContour \t\t 0 \t\t ['Lvl' 'Lvl' 'Lvl']\n",
      "LandSlope \t\t 0 \t\t ['Gtl' 'Gtl' 'Gtl']\n",
      "LotArea \t\t 0 \t\t [ 8450  9600 11250]\n",
      "LotConfig \t\t 0 \t\t ['Inside' 'FR2' 'Inside']\n",
      "LotFrontage \t\t 486 \t\t [65. 80. 68.]\n",
      "LotShape \t\t 0 \t\t ['Reg' 'Reg' 'IR1']\n",
      "LowQualFinSF \t\t 0 \t\t [0 0 0]\n",
      "MSSubClass \t\t 0 \t\t [60 20 60]\n",
      "MSZoning \t\t 4 \t\t ['RL' 'RL' 'RL']\n",
      "MasVnrArea \t\t 23 \t\t [196.   0. 162.]\n",
      "MasVnrType \t\t 24 \t\t ['BrkFace' 'None' 'BrkFace']\n",
      "MiscFeature \t\t 2814 \t\t [nan nan nan]\n",
      "MiscVal \t\t 0 \t\t [0 0 0]\n",
      "MoSold \t\t 0 \t\t [2 5 9]\n",
      "Neighborhood \t\t 0 \t\t ['CollgCr' 'Veenker' 'CollgCr']\n",
      "OpenPorchSF \t\t 0 \t\t [61  0 42]\n",
      "OverallCond \t\t 0 \t\t [5 8 5]\n",
      "OverallQual \t\t 0 \t\t [7 6 7]\n",
      "PavedDrive \t\t 0 \t\t ['Y' 'Y' 'Y']\n",
      "PoolArea \t\t 0 \t\t [0 0 0]\n",
      "PoolQC \t\t 2909 \t\t [nan nan nan]\n",
      "RoofMatl \t\t 0 \t\t ['CompShg' 'CompShg' 'CompShg']\n",
      "RoofStyle \t\t 0 \t\t ['Gable' 'Gable' 'Gable']\n",
      "SaleCondition \t\t 0 \t\t ['Normal' 'Normal' 'Normal']\n",
      "SalePrice \t\t 1459 \t\t [208500. 181500. 223500.]\n",
      "SaleType \t\t 1 \t\t ['WD' 'WD' 'WD']\n",
      "ScreenPorch \t\t 0 \t\t [0 0 0]\n",
      "Street \t\t 0 \t\t ['Pave' 'Pave' 'Pave']\n",
      "TotRmsAbvGrd \t\t 0 \t\t [8 6 6]\n",
      "TotalBsmtSF \t\t 1 \t\t [ 856. 1262.  920.]\n",
      "Utilities \t\t 2 \t\t ['AllPub' 'AllPub' 'AllPub']\n",
      "WoodDeckSF \t\t 0 \t\t [  0 298   0]\n",
      "YearBuilt \t\t 0 \t\t [2003 1976 2001]\n",
      "YearRemodAdd \t\t 0 \t\t [2003 1976 2002]\n",
      "YrSold \t\t 0 \t\t [2008 2007 2008]\n"
     ]
    }
   ],
   "source": [
    "print('Column \\t Number of Empty Entries \\t First 3 Entries')\n",
    "for col in df.columns:\n",
    "    print('{} \\t\\t {} \\t\\t {}'.format(col, df[col].isnull().sum(), df[col].values[0:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the first feature engineering plan I made from this and the data dictionary was hardly more helpful than just outright dummy encoding everything (rmsle of about 0.15 on Kaggle). This second plan will hopefully improve upon the first. What I neglected to realize was that some of the missing entries actually tell a story of their own; they can be important. Additionally, I didn't do enough feature extraction from the columns, so I'll try doing more of that as well. Here's the plan:\n",
    "\n",
    "\n",
    "### 1stFlrSF \n",
    "+ leave as is\n",
    "\n",
    "### 2ndFlrSF \n",
    "+ leave as is\n",
    "\n",
    "### 3SsnPorch \n",
    "+ leave as is\n",
    "\n",
    "### Alley \n",
    "+ set NaNs to NA's\n",
    "+ dummy encode\n",
    "\n",
    "### BedroomAbvGr \n",
    "+ leave as is\n",
    "\n",
    "### BldgType \n",
    "+ dummy encode\n",
    "\n",
    "### BsmtCond \n",
    "+ when missing: \n",
    "1. total bsmt sqft is 0.0 or NaN ==> NA\n",
    "2. total bsmt sqft > 0.0 and is not NaN ==> TA\n",
    "+ ordinal encode\n",
    "\n",
    "### BsmtExposure\n",
    "+ when missing:\n",
    "1. total bsmt sqft is 0.0 or NaN ==> NA\n",
    "2. total bsmt sqft > 0.0 ==> No\n",
    "+ ordinal encode\n",
    "\n",
    "### BsmtFinSF1  and BsmtFinSF2\n",
    "+ drop; not reliable: when Unf, often does not add up to BsmtUnfSF\n",
    "\n",
    "### BsmtFinType1 and BsmtFinType2\n",
    "+ set NaN to NA\n",
    "\n",
    "### BsmtFullBath\n",
    "+ set 2 NaN to 0’s\n",
    "\n",
    "### BsmtHalfBath\n",
    "+ set 2 NaN to 0’s\n",
    "\n",
    "### BsmtQual\n",
    "+ when missing:\n",
    "1. total bsmt sqft is 0.0 or NaN ==> NA\n",
    "2. total bsmt sqft > 0.0 ==> TA\n",
    "+ ordinal encode\n",
    "\n",
    "### BsmtUnfSF\n",
    "+ set 1 NaN to 0\n",
    "\n",
    "### CentralAir\n",
    "+ binary encode\n",
    "\n",
    "### Condition1 and Condition2\n",
    "+ combined into 9 binary columns\n",
    "\n",
    "### Electrical\n",
    "+ set 1 NaN to ‘Mix’\n",
    "+ dummy encode\n",
    "\n",
    "### EnclosedPorch\n",
    "+ leave as is\n",
    "\n",
    "### ExterCond\n",
    "+ ordinal encode\n",
    "\n",
    "### ExterQual\n",
    "+ ordinal encode\n",
    "\n",
    "### Exterior1st and Exterior2nd\n",
    "+ 1 NaN to ‘Other’\n",
    "+ combined into 17 binary columns\n",
    "\n",
    "### Fence\n",
    "+ There are no NA’s in the data set, so it’s safe to set all NaNs to NA’s\n",
    "+ dummy encode\n",
    "\n",
    "### FireplaceQu\n",
    "+ There are no NA’s in the data set, so it’s safe to set all NaNs to NA’s\n",
    "+ No instance where NaN here but != Fireplaces (count col)\n",
    "+ ordinal encode\n",
    "\n",
    "### Foundation\n",
    "+ dummy encode\n",
    "\n",
    "### FullBath\n",
    "+ leave as is\n",
    "\n",
    "### Functional\n",
    "+ 2 NaNs to Typ since “Assume typical unless deductions are warranted”\n",
    "+ ordinal encode; Typ=0 and Sal=7\n",
    "\n",
    "### Garage Area\n",
    "+ 1 NaN impute average GarageArea\n",
    "+ leave as is otherwise\n",
    "\n",
    "### GarageCars\n",
    "+ 1 NaN impute average GarageCars\n",
    "+ leave as is otherwise\n",
    "\n",
    "### GarageCond\n",
    "+ No NA’s in dataset, so it’s safe to make all NaNs NA’s\n",
    "+ ordinal encode\n",
    "\n",
    "### GarageFinish\n",
    "+ No NA’s in dataset, so it’s safe to make all NaNs NA’s\n",
    "+ ordinal encode\n",
    "\n",
    "### GarageQual\n",
    "+ No NA’s in dataset, so it’s safe to make all NaNs NA’s\n",
    "+ ordinal encode\n",
    "\n",
    "### GarageType\n",
    "+ No NA’s in dataset, so it’s safe to make all NaNs NA’s\n",
    "+ dumm encode\n",
    "\n",
    "### GarageYrBlt\n",
    "+ so as to not throw off any regressor, all NaNs to average YrBlt\n",
    "\n",
    "### GrLivArea\n",
    "+ leave as is\n",
    "\n",
    "### HalfBath\n",
    "+ leave as is\n",
    "\n",
    "### Heating\n",
    "+ dummy encode\n",
    "\n",
    "### HeatingQC\n",
    "+ ordinal encode\n",
    "\n",
    "### HouseStyle\n",
    "+ convert to num floors\n",
    "\n",
    "### Id\n",
    "+ leave as is\n",
    "\n",
    "### KitchenAbvGr\n",
    "+ leave as is\n",
    "\n",
    "### KitchenQual\n",
    "+ 1 NaN to TA\n",
    "\n",
    "### LandContour\n",
    "+ dummy encode\n",
    "\n",
    "### LandSlope\n",
    "+ ordinal encode\n",
    "\n",
    "### LotArea\n",
    "+ leave as is\n",
    "\n",
    "### LotConfig\n",
    "+ dummy encode\n",
    "\n",
    "### LotFrontage\n",
    "+ there are no 0’s; NaNs to 0’s\n",
    "\n",
    "### LotShape\n",
    "+ ordinal encode\n",
    "\n",
    "### LowQualFinSF\n",
    "+ leave as is\n",
    "\n",
    "### MSSubClass\n",
    "+ drop; don’t know what to do with it and the numbers themselves aren’t ordinal\n",
    "\n",
    "### MSZoning\n",
    "+ dummy encode\n",
    "\n",
    "### MasVnrArea\n",
    "+ there ARE 0’s, so can’t assume NaNs are 0’s too\n",
    "+ however, looking at MasVnrType, and Exterior1st and Exterior2nd and \n",
    "MasVnrType when Exterior is stone or Cblock etc., it \n",
    "is evident that there these should be 0 and MasVnrType should be None\n",
    ":: df[ df.MasVnrArea.isnull() ][[col for col in df.columns if 'Mas' in col or 'Exter' in col]]\n",
    "\n",
    "### MasVnrType\n",
    "+ set NaNs to None’s (see MasVnrArea)\n",
    "+ dummy encode\n",
    "\n",
    "### MiscFeature\n",
    "+ set NaNs to NA's\n",
    "+ binary encode present/not present\n",
    "\n",
    "### MiscValue\n",
    "+ leavea as is\n",
    "\n",
    "### MoSold\n",
    "+ leave as is\n",
    "\n",
    "### Neighborhood\n",
    "+ dummy encode\n",
    "\n",
    "### OpenPorchSF\n",
    "+ leave as is\n",
    "\n",
    "### OverallCond\n",
    "+ leave as is\n",
    "\n",
    "### PavedDrive\n",
    "+ binary encode Y=1\n",
    "\n",
    "### PoolArea\n",
    "+ leave as is\n",
    "\n",
    "### PoolQC\n",
    "+ there are no NA’s in the data; NaNs to NA’s\n",
    "+ ordinal encode\n",
    "\n",
    "### RoofMatl\n",
    "+ dummy encode\n",
    "\n",
    "### RoofStyle\n",
    "+ dummy encode\n",
    "\n",
    "### SaleCondition\n",
    "+ dummy encode\n",
    "\n",
    "### SalePrice\n",
    "+ should have NaNs for test.csv, so it’s O.K.\n",
    "\n",
    "### SaleType\n",
    "+ set 1 NaN to Oth\n",
    "+ dummy encode\n",
    "\n",
    "### ScreenPorch\n",
    "+ leave as is\n",
    "\n",
    "### Street\n",
    "+ ordinal encode\n",
    "\n",
    "### TotRmsAbvGrd\n",
    "+ leave as is\n",
    "\n",
    "### TotalBsmtSF\n",
    "+ set 1 NaN to 0\n",
    "\n",
    "### Utilities\n",
    "+ set NaNs to ELO (electrical only)\n",
    "+ ordinal encode\n",
    "\n",
    "### WoodDeckSF\n",
    "+ leave as is\n",
    "\n",
    "### YearBuilt\n",
    "+ leave as is\n",
    "\n",
    "### YearRemodAdd\n",
    "+ leave as is\n",
    "\n",
    "### YrSold\n",
    "+ leave as is\n",
    "\n",
    "\n",
    "i. idea: add 1stf and 2ndflr together to get total square feet + garage square feet + 3SsnPorch + Bsmtsqft  + enclosedPorch(sqft) + openporchsf (maybe not this)\n",
    "\n",
    "ii. idea: add BedroomAbvGr and living quarters area from BsmtFinType1 and BsmtFinType2\n",
    "\n",
    "iii. idea: add fullbath and halfbath to bsmtfullbath and bsmthalfbath, add bsmtfullbath and fullbath, add halfbath and bsmthalfbath, and add bsmtfullbath and bsmthalfbath\n",
    "\n",
    "iv. idea: add GrLivArea and TotalBsmtSF to get total living area?\n",
    "\n",
    "v. idea: (garage + 1st flr sqft + wood deck + porch stuff) / lot size get a proportion of open space?\n",
    "\n",
    "vi. idea: assign to MSZoning an ordinal density as ordinal\n",
    "\n",
    "vii. idea: use porch sqft things to binary encode porch cols, e.g., Has_WoodDeck column\n",
    "\n",
    "viii. idea: outside area = wooddeck + openporch + pool area\n",
    "\n",
    "\n",
    "It seems that the best thing to do first would be to replace all of the NaNs (missing entries) with whatever the plan specifices as their replacement. So, let's do that first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alley\n",
    "df['Alley'] = df['Alley'].fillna(value='NA')\n",
    "\n",
    "# BsmtCond NaNs\n",
    "temp_col = []\n",
    "for idx in df.index:\n",
    "    bsmt_cond = df['BsmtCond'].at[idx]\n",
    "    \n",
    "    # if missing entry\n",
    "    if pandas.isna(bsmt_cond):\n",
    "        bsmt_sf = df['TotalBsmtSF'].at[idx]\n",
    "        \n",
    "        # if TotalBsmtSF is 0 or missing ==> no basement\n",
    "        if bsmt_sf <= 0.0 or pandas.isna(bsmt_sf):\n",
    "            temp_col.append('NA')\n",
    "            \n",
    "        # else, there is a basement\n",
    "        else:\n",
    "            temp_col.append('TA')\n",
    "    # no missing entry\n",
    "    else:\n",
    "        temp_col.append(bsmt_cond)\n",
    "        \n",
    "df['BsmtCond'] = temp_col\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BsmtExposure NaNs\n",
    "temp_col = []\n",
    "for idx in df.index:\n",
    "    bsmt_cond = df['BsmtExposure'].at[idx]\n",
    "    \n",
    "    # if missing entry\n",
    "    if pandas.isna(bsmt_cond):\n",
    "        bsmt_sf = df['TotalBsmtSF'].at[idx]\n",
    "        \n",
    "        # if TotalBsmtSF is 0 or missing ==> no basement\n",
    "        if bsmt_sf <= 0.0 or pandas.isna(bsmt_sf):\n",
    "            temp_col.append('NA')\n",
    "            \n",
    "        # else, there is a basement\n",
    "        else:\n",
    "            temp_col.append('No')\n",
    "    # no missing entry\n",
    "    else:\n",
    "        temp_col.append(bsmt_cond)\n",
    "        \n",
    "df['BsmtExposure'] = temp_col\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop those 2 unreliable basement columns\n",
    "df = df.drop(['BsmtFinSF1', 'BsmtFinSF2'], axis=1)\n",
    "\n",
    "# Drop MSSubClass since not know what to do with IDs, at least for now\n",
    "df = df.drop(['MSSubClass'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BsmtFinType1 and 2 NaNs\n",
    "temp_bsmt1_col = []\n",
    "temp_bsmt2_col = []\n",
    "for idx in df.index:\n",
    "    bsmt_1 = df['BsmtFinType1'].at[idx]\n",
    "    bsmt_2 = df['BsmtFinType2'].at[idx]\n",
    "    \n",
    "    # BsmtFinType1 \n",
    "    if pandas.isna(bsmt_1):\n",
    "        temp_bsmt1_col.append('NA')\n",
    "    else:\n",
    "        temp_bsmt1_col.append(bsmt_1)\n",
    "        \n",
    "    # BsmtFinType2\n",
    "    if pandas.isna(bsmt_2):\n",
    "        temp_bsmt2_col.append('NA')\n",
    "    else:\n",
    "        temp_bsmt2_col.append(bsmt_2)\n",
    "        \n",
    "df['BsmtFinType1'] = temp_bsmt1_col\n",
    "df['BsmtFinType2'] = temp_bsmt2_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BsmtFullBath\n",
    "df['BsmtFullBath'] = df['BsmtFullBath'].fillna(value=0)\n",
    "\n",
    "# BsmtHalfBath\n",
    "df['BsmtHalfBath'] = df['BsmtHalfBath'].fillna(value=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BsmtQual\n",
    "temp_col = []\n",
    "for idx in df.index:\n",
    "    bsmt_qual = df['BsmtQual'].at[idx]\n",
    "    \n",
    "    # if missing entry\n",
    "    if pandas.isna(bsmt_qual):\n",
    "        bsmt_sf = df['TotalBsmtSF'].at[idx]\n",
    "        \n",
    "        # if TotalBsmtSF is 0 or missing ==> no basement\n",
    "        if bsmt_sf <= 0.0 or pandas.isna(bsmt_sf):\n",
    "            temp_col.append('NA')\n",
    "            \n",
    "        # else, there is a basement\n",
    "        else:\n",
    "            temp_col.append('TA')\n",
    "    # no missing entry\n",
    "    else:\n",
    "        temp_col.append(bsmt_qual)\n",
    "        \n",
    "df['BsmtQual'] = temp_col\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BsmtUnfSF\n",
    "df['BsmtUnfSF'] = df['BsmtUnfSF'].fillna(value=0)\n",
    "\n",
    "# Electrical\n",
    "df['Electrical'] = df['Electrical'].fillna(value='Mix')\n",
    "\n",
    "# Exterior1st\n",
    "df['Exterior1st'] = df['Exterior1st'].fillna(value='Other')\n",
    "\n",
    "# Exterior2nd\n",
    "df['Exterior2nd'] = df['Exterior2nd'].fillna(value='Other')\n",
    "\n",
    "# Fence\n",
    "df['Fence'] = df['Fence'].fillna(value='NA')\n",
    "\n",
    "# FireplaceQu\n",
    "df['FireplaceQu'] = df['FireplaceQu'].fillna(value='NA')\n",
    "\n",
    "# Functional\n",
    "df['Functional'] = df['Functional'].fillna(value='Typ')\n",
    "\n",
    "# GarageArea\n",
    "df['GarageArea'] = df['GarageArea'].fillna(value=df['GarageArea'].mean())\n",
    "\n",
    "# GarageCars\n",
    "df['GarageCars'] = df['GarageCars'].fillna(value=df['GarageCars'].mean())\n",
    "\n",
    "# GarageCond\n",
    "df['GarageCond'] = df['GarageCond'].fillna(value='NA')\n",
    "\n",
    "# GarageFinish\n",
    "df['GarageFinish'] = df['GarageFinish'].fillna(value='NA')\n",
    "\n",
    "# GarageQual\n",
    "df['GarageQual'] = df['GarageQual'].fillna(value='NA')\n",
    "\n",
    "# GarageType\n",
    "df['GarageType'] = df['GarageType'].fillna(value='NA')\n",
    "\n",
    "# GarageYrBlt\n",
    "df['GarageYrBlt'] = df['GarageYrBlt'].fillna(value=df['GarageYrBlt'].mean())\n",
    "\n",
    "# KitchenQual\n",
    "df['KitchenQual'] = df['KitchenQual'].fillna(value='TA')\n",
    "\n",
    "# LotFrontage\n",
    "df['LotFrontage'] = df['LotFrontage'].fillna(value=0)\n",
    "\n",
    "# MasVnrArea\n",
    "df['MasVnrArea'] = df['MasVnrArea'].fillna(value=0)\n",
    "\n",
    "# MasVnrType\n",
    "df['MasVnrType'] = df['MasVnrType'].fillna(value='None')\n",
    "\n",
    "# MiscFeature\n",
    "df['MiscFeature'] = df['MiscFeature'].fillna(value='NA')\n",
    "\n",
    "# PoolQC\n",
    "df['PoolQC'] = df['PoolQC'].fillna(value='NA')\n",
    "\n",
    "# SaleType\n",
    "df['SaleType'] = df['SaleType'].fillna(value='Oth')\n",
    "\n",
    "# TotalBsmtSF\n",
    "df['TotalBsmtSF'] = df['TotalBsmtSF'].fillna(value=0)\n",
    "\n",
    "# Utilities\n",
    "df['Utilities'] = df['Utilities'].fillna(value='ELO')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That covers all of the NaNs/missing entries except for SalePrice which should have missing entries since that is what we are trying to predict in test.csv. The next step is to binary and ordinal encode all relevant columns. Dummy encoding will come later because it will be done just by doing pandas.get_dummies(df). This funciton will split all columns that are not numerical columns into binary columns, the number of which is equal to the number of unique values in that non-numerical column. This is not something that should be done to columns that just will be binary encoded (since it would split into 2 columns when 1 is sufficient) nor to columns that will be ordinal encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_encode(df, col_name, conversion_dict):\n",
    "    \"\"\"\n",
    "    df = dataframe with whole data set\n",
    "    col_name = name of col want to label encode\n",
    "    conversion_dict = keys are all current unique values\n",
    "    and corresponding values in the dict are the values to\n",
    "    which the labels should be encoded\n",
    "    \"\"\"\n",
    "    encoded_col = []\n",
    "    for entry in df[col_name]:\n",
    "        encoded_col.append( conversion_dict[entry] )\n",
    "           \n",
    "    return encoded_col\n",
    "\n",
    "bsmtcond_dict = {'Ex': 5,\n",
    "                 'Gd': 4,\n",
    "                 'TA': 3,\n",
    "                 'Fa': 2,\n",
    "                 'Po': 1,\n",
    "                 'NA': 0}\n",
    "df['BsmtCond'] = ordinal_encode(df, 'BsmtCond', bsmtcond_dict)\n",
    "\n",
    "bsmtexposure_dict = {'Gd': 4,\n",
    "                     'Av': 3, \n",
    "                     'Mn': 2,\n",
    "                     'No': 1,\n",
    "                     'NA': 0}\n",
    "df['BsmtExposure'] = ordinal_encode(df, 'BsmtExposure', bsmtexposure_dict)\n",
    "\n",
    "bsmtqual_dict = {'Ex': 5,\n",
    "                 'Gd': 4,\n",
    "                 'TA': 3,\n",
    "                 'Fa': 2,\n",
    "                 'Po': 1,\n",
    "                 'NA': 0}\n",
    "df['BsmtQual'] = ordinal_encode(df, 'BsmtQual', bsmtqual_dict)\n",
    "\n",
    "df['CentralAir'] = (df['CentralAir'] == True) * 1\n",
    "\n",
    "extercond_dict = {'Ex': 5,\n",
    "                  'Gd': 4,\n",
    "                  'TA': 3,\n",
    "                  'Fa': 2,\n",
    "                  'Po': 1,}\n",
    "df['ExterCond'] = ordinal_encode(df, 'ExterCond', extercond_dict)\n",
    "\n",
    "exterqual_dict = extercond_dict\n",
    "df['ExterQual'] = ordinal_encode(df, 'ExterQual', exterqual_dict)\n",
    "\n",
    "fireplacequ_dict = {'Ex': 5,\n",
    "                    'Gd': 4,\n",
    "                    'TA': 3,\n",
    "                    'Fa': 2,\n",
    "                    'Po': 1,\n",
    "                    'NA': 0}\n",
    "df['FireplaceQu'] = ordinal_encode(df, 'FireplaceQu', fireplacequ_dict)\n",
    "\n",
    "functional_dict = {'Typ': 0,\n",
    "                   'Min1': 1,\n",
    "                   'Min2': 2,\n",
    "                   'Mod': 3,\n",
    "                   'Maj1': 4,\n",
    "                   'Maj2': 5,\n",
    "                   'Sev': 6, \n",
    "                   'Sal': 7}\n",
    "df['Functional'] = ordinal_encode(df, 'Functional', functional_dict)\n",
    "\n",
    "garagecond_dict = {'Ex': 5,\n",
    "                   'Gd': 4,\n",
    "                   'TA': 3,\n",
    "                   'Fa': 2,\n",
    "                   'Po': 1,\n",
    "                   'NA': 0}\n",
    "df['GarageCond'] = ordinal_encode(df, 'GarageCond', garagecond_dict)\n",
    "\n",
    "garagefinish_dict = {'Fin': 3,\n",
    "                     'RFn': 2,\n",
    "                     'Unf': 1,\n",
    "                     'NA': 0}\n",
    "df['GarageFinish'] = ordinal_encode(df, 'GarageFinish', garagefinish_dict)\n",
    "\n",
    "garagequal_dict = {'Ex': 5,\n",
    "                   'Gd': 4,\n",
    "                   'TA': 3,\n",
    "                   'Fa': 2,\n",
    "                   'Po': 1,\n",
    "                   'NA': 0}\n",
    "df['GarageQual'] = ordinal_encode(df, 'GarageQual', garagequal_dict)\n",
    "\n",
    "heatingqc_dict = {'Ex': 5,\n",
    "                  'Gd': 4,\n",
    "                  'TA': 3,\n",
    "                  'Fa': 2,\n",
    "                  'Po': 1}\n",
    "df['HeatingQC'] = ordinal_encode(df, 'HeatingQC', heatingqc_dict)\n",
    "\n",
    "kitchenqual_dict = {'Ex': 5,\n",
    "                    'Gd': 4,\n",
    "                    'TA': 3,\n",
    "                    'Fa': 2,\n",
    "                    'Po': 1,}\n",
    "df['KitchenQual'] = ordinal_encode(df, 'KitchenQual', kitchenqual_dict)\n",
    "\n",
    "landslope_dict = {'Gtl': 1,\n",
    "                  'Mod': 2,\n",
    "                  'Sev': 3,}\n",
    "df['LandSlope'] = ordinal_encode(df, 'LandSlope', landslope_dict)\n",
    "\n",
    "lotshape_dict = {'Reg': 1,\n",
    "                 'IR1': 2,\n",
    "                 'IR2': 3, \n",
    "                 'IR3': 4}\n",
    "df['LotShape'] = ordinal_encode(df, 'LotShape', lotshape_dict)\n",
    "\n",
    "paveddrive_dict  ={'Y': 3,\n",
    "                   'P': 2,\n",
    "                   'N': 1}\n",
    "df['PavedDrive'] = ordinal_encode(df, 'PavedDrive', paveddrive_dict)\n",
    "\n",
    "poolqc_dict = {'Ex': 4,\n",
    "               'Gd': 3,\n",
    "               'TA': 2,\n",
    "               'Fa': 1,\n",
    "               'NA': 0}\n",
    "df['PoolQC'] = ordinal_encode(df, 'PoolQC', poolqc_dict)\n",
    "\n",
    "df['Street_Paved'] = (df['Street'] == 'Pave') * 1\n",
    "df = df.drop('Street', axis=1)\n",
    "\n",
    "utilities_dict = {'AllPub': 4,\n",
    "                  'NoSewr': 3,\n",
    "                  'NoSeWa': 2,\n",
    "                  'ELO': 1}\n",
    "df['Utilities'] = ordinal_encode(df, 'Utilities', utilities_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the NaNs have been replaced and all relevant columns have been binary or ordinal encoded, the next order of business is to combine the columns that should be combined. There are only two such sets columns: Condition1 and Condition2; Exterior1st and Exterior2nd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_cols = ['Condition_Artery',\n",
    "                  'Condition_Feedr',\n",
    "                  'Condition_Norm',\n",
    "                  'Condition_RRNn',\n",
    "                  'Condition_RRAn',\n",
    "                  'Condition_PosN',\n",
    "                  'Condition_PosA',\n",
    "                  'Condition_RRNe',\n",
    "                  'Condition_RRAe',\n",
    "                  'Condition_Artery',\n",
    "                  'Conditions']\n",
    "\n",
    "# Initialize these columns to all 0's\n",
    "for col in condition_cols:\n",
    "    df[col] = 0\n",
    "    \n",
    "num_conditions_list = []\n",
    "for idx, condition_1, condition_2 in zip(df.index,\n",
    "                                         df['Condition1'].values,\n",
    "                                         df['Condition2'].values):\n",
    "    num_conditions = 2\n",
    "    for entry in [condition_1, condition_2]:\n",
    "        \n",
    "        if entry == 'Norm':\n",
    "            num_conditions -= 1\n",
    "            df['Condition_Norm'].at[idx] = 1\n",
    "            \n",
    "        elif entry == 'Artery':\n",
    "            df['Condition_Artery'].at[idx] = 1\n",
    "            \n",
    "        elif entry == 'Feedr':\n",
    "            df['Condition_Feedr'].at[idx] = 1\n",
    "            \n",
    "        elif entry == 'RRNn':\n",
    "            df['Condition_RRNn'].at[idx] = 1\n",
    "            \n",
    "        elif entry == 'RRAn':\n",
    "            df['Condition_RRAn'].at[idx] = 1\n",
    "            \n",
    "        elif entry == 'PosN':\n",
    "            df['Condition_PosN'].at[idx] = 1\n",
    "            \n",
    "        elif entry == 'PosA':\n",
    "            df['Condition_PosA'].at[idx] = 1\n",
    "            \n",
    "        elif entry == 'RRNe':\n",
    "            df['Condition_RRNe'].at[idx] = 1\n",
    "            \n",
    "        else:\n",
    "            df['Condition_RRAe'].at[idx] = 1\n",
    "            \n",
    "    num_conditions_list.append(num_conditions)\n",
    "            \n",
    "df['Conditions'] = num_conditions_list\n",
    "df = df.drop(['Condition1', 'Condition2'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same thing for Exterior1st and Exterior2nd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a better way to do this sort of encoding\n",
    "exterior_values_list = np.unique( np.append(df['Exterior1st'].values,\n",
    "                                            df['Exterior2nd'].values) )\n",
    "\n",
    "# Create thos column names automatically (created manually before)\n",
    "new_exterior_cols_list = []\n",
    "for possible_value in exterior_values_list:\n",
    "    new_exterior_cols_list.append( 'Exterior_{}'.format(possible_value))\n",
    "\n",
    "# Initialize these columns to all 0's\n",
    "for col in new_exterior_cols_list:\n",
    "    df[col] = 0\n",
    "    \n",
    "# Much better than having 17 if-elif-else statements\n",
    "for idx, exterior_1, exterior_2 in zip(df.index,\n",
    "                                       df['Exterior1st'].values,\n",
    "                                       df['Exterior2nd'].values):\n",
    "    for entry in [exterior_1, exterior_2]:\n",
    "        df['Exterior_{}'.format(entry)].at[idx] = 1\n",
    "        \n",
    "            \n",
    "            \n",
    "df = df.drop(['Exterior1st', 'Exterior2nd'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All that remains in this feature engineering plan is extracting the number of stories from HouseStyle, implementing some of those 8 ideas, and dummy encoding the remaining object columns. We'll do all of those things in that order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for number of stories\n",
    "housestyle_num_stories_dict = {'1Story': 1.0,\n",
    "                               '1.5Fin': 1.5,\n",
    "                               '1.5Unf': 1.5,\n",
    "                               '2Story': 2.0, \n",
    "                               '2.5Fin': 2.5,\n",
    "                               '2.5Unf': 2.5,\n",
    "                               'SFoyer': 1.5,\n",
    "                                'SLvl': 1.5,}\n",
    "df['NumStories'] = ordinal_encode(df, 'HouseStyle', \n",
    "                                housestyle_num_stories_dict)\n",
    "\n",
    "# Add column for finished/not finished\n",
    "housestyle_finished_dict = {'1Story': 1,\n",
    "                           '1.5Fin': 1,\n",
    "                           '1.5Unf': 0,\n",
    "                           '2Story': 1, \n",
    "                           '2.5Fin': 1,\n",
    "                           '2.5Unf': 0,\n",
    "                           'SFoyer': 1,\n",
    "                            'SLvl': 1,}\n",
    "df['Finished'] = ordinal_encode(df, 'HouseStyle',\n",
    "                              housestyle_finished_dict)\n",
    "\n",
    "# Add column for any splitting or not\n",
    "housestyle_split_dict = {'1Story': 0,\n",
    "                       '1.5Fin': 1,\n",
    "                       '1.5Unf': 1,\n",
    "                       '2Story': 0, \n",
    "                       '2.5Fin': 1,\n",
    "                       '2.5Unf': 1,\n",
    "                       'SFoyer': 1,\n",
    "                        'SLvl': 1,}\n",
    "df['SplitStories'] = ordinal_encode(df, 'HouseStyle', \n",
    "                                  housestyle_split_dict)\n",
    "\n",
    "# These columns aren't really replacing HouseStyle, so not dropping HouseStyle\n",
    "#df = df.drop('HouseStyle', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start going through and implementing some of the ideas. The first idea is to do: 1stFlrSF + 2ndFlrSF + GarageArea + 3SsnPoch + EnclosedPorch + OpenPorchSF + ScreenPorch + TotalBsmtSF. This should be close to the size of the house altogether. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea No. 1\n",
    "df['HouseAltogther'] = 0   # column of 0's\n",
    "for idx in df.index:\n",
    "    df['HouseAltogther'].at[idx] = df['1stFlrSF'].at[idx] +\\\n",
    "                                   df['2ndFlrSF'].at[idx] +\\\n",
    "                                   df['GarageArea'].at[idx] +\\\n",
    "                                   df['3SsnPorch'].at[idx] +\\\n",
    "                                   df['EnclosedPorch'].at[idx] +\\\n",
    "                                   df['OpenPorchSF'].at[idx] +\\\n",
    "                                   df['ScreenPorch'].at[idx] +\\\n",
    "                                   df['TotalBsmtSF'].at[idx]\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea No. 2 is to add BedroomAbvGr to the number of bedrooms in the basement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea No. 2\n",
    "df['NumBedrooms'] = 0\n",
    "bsmt_bedrooms = ['GLQ', 'ALQ', 'BLQ']\n",
    "for idx in df.index:\n",
    "    df['NumBedrooms'].at[idx] = df['BedroomAbvGr'].at[idx] +\\\n",
    "                                (df['BsmtFinType1'].at[idx] in bsmt_bedrooms)*1 +\\\n",
    "                                (df['BsmtFinType2'].at[idx] in bsmt_bedrooms)*1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea No. 3 is to get the total number of baths in the house, the total number of baths in the basement, the total number of full baths, and the total number of half baths. This is useful because basement baths are not counted in FullBath or HalfBath; those two only count ``above grade'' baths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea No. 3\n",
    "df['TotalBath'] = 0\n",
    "df['TotalFullBath'] = 0\n",
    "df['TotalHalfBath'] = 0\n",
    "df['TotalBsmtBath'] = 0\n",
    "for idx in df.index:\n",
    "    above_full = df['FullBath'].at[idx]\n",
    "    above_half = df['HalfBath'].at[idx]\n",
    "    bsmt_full = df['BsmtFullBath'].at[idx]\n",
    "    bsmt_half = df['BsmtHalfBath'].at[idx]\n",
    "    \n",
    "    df['TotalBath'].at[idx] = above_full + above_half + bsmt_full + bsmt_half\n",
    "    df['TotalFullBath'].at[idx] = above_full + bsmt_full\n",
    "    df['TotalHalfBath'].at[idx] = above_half + bsmt_half\n",
    "    df['TotalBsmtBath'].at[idx] = bsmt_full + bsmt_half\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea No. 4 is to add GrLivArea and TotalBsmtSqft to get another measurement of the size of the house altogether. This one differs slightly from HouseAltogether in that it only includes that which is indoors, i.e., decks, garages, porches are exclued. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea No. 4\n",
    "df['LivingArea'] = 0\n",
    "for idx in df.index:\n",
    "    df['LivingArea'].at[idx] = df['GrLivArea'].at[idx] + df['TotalBsmtSF'].at[idx]\n",
    "                                                                                                                                                                  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea No. 5 tries to calculate the proportion of the lot that the structure takes up. This proportion is: (GarageArea + 1stFlrSF + WoodDeck + OpenPorchSF + EnclosedPorchSF + 3SsnPoch + ScreenPorch + PoolArea) / LotArea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea No. 5\n",
    "df['HouseToLot'] = 0.0   # house to lot as in \"hosue to lot ratio\"\n",
    "for idx in df.index:\n",
    "    sum_of_areas = (df['GarageArea'].at[idx] +\\\n",
    "                   df['1stFlrSF'].at[idx] +\\\n",
    "                   df['WoodDeckSF'].at[idx] +\\\n",
    "                   df['OpenPorchSF'].at[idx] +\\\n",
    "                   df['EnclosedPorch'].at[idx] +\\\n",
    "                   df['3SsnPorch'].at[idx]) +\\\n",
    "                   df['ScreenPorch'].at[idx] +\\\n",
    "                   df['PoolArea'].at[idx]\n",
    "    \n",
    "    df['HouseToLot'].at[idx] = sum_of_areas / float(df['LotArea'].at[idx])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea No. 6 is to try and extract density from MSZoning not just for the residential entries, but also for agricultural, commercial, floating village, and industrial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea No. 6\n",
    "density_dict = {'A': 1,\n",
    "                'C (all)': 2,\n",
    "                'FV': 1,\n",
    "                'I': 2,\n",
    "                'RH': 3,\n",
    "                'RL': 1,\n",
    "                'RP': 1,\n",
    "                'RM': 2,\n",
    "                np.nan: 1}\n",
    "df['Density'] = 0\n",
    "for idx in df.index:\n",
    "    df['Density'].at[idx] = density_dict[ df['MSZoning'].at[idx] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea No. 7 is to use the Porch and WoodDeck columns to create binary columns for each respective type, e.g., want Has_WoodDeck as a column of 1's and 0's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea No. 7\n",
    "deck_and_porch_cols = ['WoodDeckSF',\n",
    "                       'OpenPorchSF',\n",
    "                       'EnclosedPorch',\n",
    "                       '3SsnPorch', \n",
    "                       'ScreenPorch']\n",
    "\n",
    "for col in deck_and_porch_cols:\n",
    "    df['Has_' + col.replace('SF', '')] = 0\n",
    "\n",
    "for idx in df.index:\n",
    "    for col in deck_and_porch_cols:\n",
    "        if df[col].at[idx] != 0:\n",
    "            df['Has_' + col.replace('SF', '')].at[idx] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, idea No. 8: add up all of the outdoor area. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdoor_cols = ['PoolArea', \n",
    "                'OpenPorchSF',\n",
    "                'WoodDeckSF']\n",
    "df['OutdoorArea'] = 0\n",
    "\n",
    "for idx in df.index:\n",
    "    outdoor_area = 0\n",
    "    for col in outdoor_cols:\n",
    "        outdoor_area += df[col].at[idx]\n",
    "    df['OutdoorArea'].at[idx] = outdoor_area\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By this point, all NaN that needed replacing have been replaced, relevant columns have been binary or ordinal encoded, the two pairs of columns have been \"combined and split\" into a number binary columns equal to the number of unique entries in one column, and the 8 ideas have been implemented. \n",
    "\n",
    "\n",
    "Now, we are ready to dummy encode everything else and get to work on model building. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.get_dummies(df.drop('SalePrice',\n",
    "                                axis=1)).join(pandas.DataFrame(df['SalePrice']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Know that there are no NaNs, but want to make sure that there are\n",
    "# no object columns that would mess with model building\n",
    "for col in df.columns:\n",
    "    if df[col].dtype == 'O':\n",
    "        print('{} \\t True'.format(col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was a lot of feature engineering, but hopefully it will be worth it. There are no columns whose data type is 'O' for 'object,' so we can start building some models to predict sale prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_train_ids = []\n",
    "current_test_ids = []\n",
    "\n",
    "# row id not necesssarily equal data frame index\n",
    "for row_id in df['Id'].values:\n",
    "    if row_id in test_csv_ids:\n",
    "        current_test_ids.append(row_id)\n",
    "    else:\n",
    "        current_train_ids.append(row_id)\n",
    "        \n",
    "current_train_indicies = sorted(current_train_ids)\n",
    "current_test_indicies = sorted(current_test_ids)\n",
    "\n",
    "df_train = df[ df.Id.isin(current_train_ids) ]\n",
    "df_test = df[ df.Id.isin(current_test_ids) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "def rmsle(y_actuals, y_predicteds):\n",
    "    return math.sqrt( mean_squared_log_error(y_actuals, y_predicteds) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test =\\\n",
    "train_test_split(df_train.drop('SalePrice', axis=1).values,\n",
    "                 df_train['SalePrice'],\n",
    "                 test_size=0.25) # 0.25 seems to be closest to the\n",
    "# Kaggle RMSLE scores when training on all of train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest training RMSLE feature engineering: 0.059759116731138866\n",
      "Random forest testing RMSLE feature engineering: 0.13997010396090362\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Random forest regressor on the feature engineered data\n",
    "rfr = RandomForestRegressor(n_estimators=200, max_depth=None)\n",
    "rfr.fit(x_train, y_train)\n",
    "\n",
    "print('Random forest training RMSLE feature engineering: {}'.format(rmsle(y_train, np.abs(rfr.predict(x_train)))) )\n",
    "print('Random forest testing RMSLE feature engineering: {}'.format(rmsle(y_test, np.abs(rfr.predict(x_test)))) )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear reg. training RMSLE feature engineering: 0.17102819779834955\n",
      "Linear reg. testing RMSLE feature engineering: 0.1981712197799799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/base.py:509: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  linalg.lstsq(X, y)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "print('Linear reg. training RMSLE feature engineering: {}'.format(rmsle(y_train, np.abs(lr.predict(x_train)))) )\n",
    "print('Linear reg. testing RMSLE feature engineering: {}'.format(rmsle(y_test, np.abs(lr.predict(x_test)))) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1stFlrSF -4.940007135862544\n",
      "2ndFlrSF 11.821352003613926\n",
      "3SsnPorch 23.264470526139885\n",
      "BedroomAbvGr -3001.3296253374483\n",
      "BsmtCond -2183.051754585634\n",
      "BsmtExposure 4977.577226032548\n",
      "BsmtFullBath -885.26261454158\n",
      "BsmtHalfBath 2450.3095240625757\n",
      "BsmtQual 6430.877675647452\n",
      "BsmtUnfSF -10.376598411834026\n",
      "CentralAir -2.0318989846453813e-08\n",
      "EnclosedPorch -8.299349163759913\n",
      "ExterCond -1720.0736333601717\n",
      "ExterQual 6547.487120824621\n",
      "FireplaceQu -1446.8025221610733\n",
      "Fireplaces 5951.662354716009\n",
      "FullBath 1179.8406103215596\n",
      "Functional -5745.637594402727\n",
      "GarageArea 21.303785508777125\n",
      "GarageCars 3539.8026554804255\n",
      "GarageCond 13.436224149903637\n",
      "GarageFinish 1701.8863837938031\n",
      "GarageQual 6753.294808999584\n",
      "GarageYrBlt -97.25218425503701\n",
      "GrLivArea 15.876933135631464\n",
      "HalfBath -1143.7379630414368\n",
      "HeatingQC 1515.5381163491252\n",
      "Id 1.6092895052339475\n",
      "KitchenAbvGr -8309.920015422054\n",
      "KitchenQual 5174.6571104334835\n",
      "LandSlope 9464.50738918917\n",
      "LotArea -0.00033135648769500037\n",
      "LotFrontage -13.337960819213656\n",
      "LotShape -1198.7880626572942\n",
      "LowQualFinSF 8.99558756643713\n",
      "MasVnrArea 24.216305038799966\n",
      "MiscVal 2.5410113952006133\n",
      "MoSold -468.54648063472024\n",
      "OpenPorchSF -91.27560214972314\n",
      "OverallCond 4043.988537747672\n",
      "OverallQual 7301.111788099546\n",
      "PavedDrive 3123.605768712101\n",
      "PoolArea 226.7195131699798\n",
      "PoolQC -52505.246636473574\n",
      "ScreenPorch 48.60073042435576\n",
      "TotRmsAbvGrd 3081.9720141047555\n",
      "TotalBsmtSF 6.168308257474354\n",
      "Utilities -1.756657025474948e-10\n",
      "WoodDeckSF -44.824778523236795\n",
      "YearBuilt 134.19537763949663\n",
      "YearRemodAdd 74.80670437626168\n",
      "YrSold -4.209088594421473\n",
      "Street_Paved 24824.449257038686\n",
      "Condition_Artery 84317.62377987405\n",
      "Condition_Feedr 81698.75814563173\n",
      "Condition_Norm -10530.821729128716\n",
      "Condition_RRNn 88797.56436966475\n",
      "Condition_RRAn 91911.24382583439\n",
      "Condition_PosN 63907.82767019116\n",
      "Condition_PosA 105272.45186889742\n",
      "Condition_RRNe 61017.79795239272\n",
      "Condition_RRAe 58968.090124418355\n",
      "Conditions -90224.69593765393\n",
      "Exterior_AsbShng 1543.0208878443875\n",
      "Exterior_AsphShn 9648.778548270868\n",
      "Exterior_Brk Cmn 34578.862779288494\n",
      "Exterior_BrkComm -24096.66021629808\n",
      "Exterior_BrkFace 13522.961081754383\n",
      "Exterior_CBlock 9657.80693729778\n",
      "Exterior_CemntBd 4393.959378501499\n",
      "Exterior_CmentBd 7758.44042012435\n",
      "Exterior_HdBoard -706.1224207830729\n",
      "Exterior_ImStucc 1193.1200159912623\n",
      "Exterior_MetalSd 6711.746914403424\n",
      "Exterior_Other -29898.69999730897\n",
      "Exterior_Plywood -1190.7425901227448\n",
      "Exterior_Stone 20086.93630918162\n",
      "Exterior_Stucco 10656.244897129765\n",
      "Exterior_VinylSd 1676.9260507027802\n",
      "Exterior_Wd Sdng 449.2503545377474\n",
      "Exterior_Wd Shng -8791.66071828449\n",
      "Exterior_WdShing 4084.5826519962684\n",
      "NumStories -18879.077522894142\n",
      "Finished -11692.367271280811\n",
      "SplitStories -2729.2656487838267\n",
      "HouseAltogther 6.64368999519193\n",
      "NumBedrooms 28.929993366522012\n",
      "TotalBath 1601.1495570837824\n",
      "TotalFullBath 294.57799582997444\n",
      "TotalHalfBath 1306.571561255736\n",
      "TotalBsmtBath 1565.046909656428\n",
      "LivingArea 22.04524011133343\n",
      "HouseToLot -89805.65863342247\n",
      "Density -2580.7412359850778\n",
      "Has_WoodDeck -4814.930731429766\n",
      "Has_OpenPorch 1633.8902812856008\n",
      "Has_EnclosedPorch 1963.4901533707225\n",
      "Has_3SsnPorch 14413.052989691168\n",
      "Has_ScreenPorch -349.5957464020148\n",
      "OutdoorArea 90.61913250644155\n",
      "Alley_Grvl -3214.7319268337537\n",
      "Alley_NA 198.73788184875593\n",
      "Alley_Pave 3015.994044985677\n",
      "BldgType_1Fam 9903.169041732155\n",
      "BldgType_2fmCon 5008.661241884205\n",
      "BldgType_Duplex -5585.721225949939\n",
      "BldgType_Twnhs -3561.1329454529205\n",
      "BldgType_TwnhsE -5764.97611221437\n",
      "BsmtFinType1_ALQ -9792.757282734023\n",
      "BsmtFinType1_BLQ -8850.48794112688\n",
      "BsmtFinType1_GLQ -3949.147588110365\n",
      "BsmtFinType1_LwQ -13770.156307571933\n",
      "BsmtFinType1_NA 58217.605578040544\n",
      "BsmtFinType1_Rec -11577.908849412031\n",
      "BsmtFinType1_Unf -10277.147609086891\n",
      "BsmtFinType2_ALQ 15304.75861403306\n",
      "BsmtFinType2_BLQ 3094.8706272342915\n",
      "BsmtFinType2_GLQ 7223.023189150788\n",
      "BsmtFinType2_LwQ 1745.7414282439386\n",
      "BsmtFinType2_NA -31735.27648405436\n",
      "BsmtFinType2_Rec -2684.8966219773392\n",
      "BsmtFinType2_Unf 7051.779247371458\n",
      "Electrical_FuseA -8400.871498839855\n",
      "Electrical_FuseF -7435.917612622607\n",
      "Electrical_FuseP 11576.45185539185\n",
      "Electrical_Mix 11783.83438846184\n",
      "Electrical_SBrkr -7523.497132391307\n",
      "Fence_GdPrv -5309.192758027511\n",
      "Fence_GdWo 4758.78099205017\n",
      "Fence_MnPrv 696.798453191323\n",
      "Fence_MnWw -916.2973326594229\n",
      "Fence_NA 769.9106454460643\n",
      "Foundation_BrkTil -2727.1273598494154\n",
      "Foundation_CBlock 2496.3754125315854\n",
      "Foundation_PConc 5013.139555010485\n",
      "Foundation_Slab 14965.949088805628\n",
      "Foundation_Stone -14634.577921699845\n",
      "Foundation_Wood -5113.758774798647\n",
      "GarageType_2Types -27303.543043257312\n",
      "GarageType_Attchd -7346.0096816193245\n",
      "GarageType_Basment 5313.422205593532\n",
      "GarageType_BuiltIn -7568.929392062831\n",
      "GarageType_CarPort 9329.02494398006\n",
      "GarageType_Detchd -1482.5531603432958\n",
      "GarageType_NA 29058.588127709343\n",
      "Heating_Floor 11257.425539859796\n",
      "Heating_GasA 17005.3709008996\n",
      "Heating_GasW 9646.421010331665\n",
      "Heating_Grav 9397.11939716707\n",
      "Heating_OthW -36537.54383926127\n",
      "Heating_Wall -10768.793008996407\n",
      "HouseStyle_1.5Fin -115.96281485593067\n",
      "HouseStyle_1.5Unf 14186.753369637978\n",
      "HouseStyle_1Story -427.8917231705203\n",
      "HouseStyle_2.5Fin -18177.215972099304\n",
      "HouseStyle_2.5Unf -2494.3860983562063\n",
      "HouseStyle_2Story 3157.1573719529197\n",
      "HouseStyle_SFoyer 1277.9737107347269\n",
      "HouseStyle_SLvl 2593.5721561558853\n",
      "LandContour_Bnk -404.2792781342066\n",
      "LandContour_HLS 14996.320038774988\n",
      "LandContour_Low -17985.770364621712\n",
      "LandContour_Lvl 3393.729603980963\n",
      "LotConfig_Corner 5664.933592304199\n",
      "LotConfig_CulDSac 13318.29437082376\n",
      "LotConfig_FR2 -4477.999832847134\n",
      "LotConfig_FR3 -16620.308135973668\n",
      "LotConfig_Inside 2115.0800056930702\n",
      "MSZoning_C (all) -10332.99092086933\n",
      "MSZoning_FV 7156.763945010464\n",
      "MSZoning_RH 2700.9808691351736\n",
      "MSZoning_RL -1875.041839889433\n",
      "MSZoning_RM 2350.287946613057\n",
      "MasVnrType_BrkCmn -7043.7280295681285\n",
      "MasVnrType_BrkFace -1373.268457452017\n",
      "MasVnrType_None 1510.1515497398696\n",
      "MasVnrType_Stone 6906.844937281161\n",
      "MiscFeature_Gar2 -7857.317507116619\n",
      "MiscFeature_NA 42095.77639622411\n",
      "MiscFeature_Othr 40124.62211098818\n",
      "MiscFeature_Shed 40797.968321563174\n",
      "MiscFeature_TenC -115161.04932165818\n",
      "Neighborhood_Blmngtn 18586.035596195245\n",
      "Neighborhood_Blueste 45642.051103646\n",
      "Neighborhood_BrDale 21443.73052695446\n",
      "Neighborhood_BrkSide -3895.5102909318002\n",
      "Neighborhood_ClearCr -15221.07751770777\n",
      "Neighborhood_CollgCr -15439.391747816968\n",
      "Neighborhood_Crawfor 7397.572452179133\n",
      "Neighborhood_Edwards -19808.71713042361\n",
      "Neighborhood_Gilbert -14688.672952505724\n",
      "Neighborhood_IDOTRR -15258.74664003447\n",
      "Neighborhood_MeadowV 2931.6360652168282\n",
      "Neighborhood_Mitchel -16573.2113547228\n",
      "Neighborhood_NAmes -14088.351367491667\n",
      "Neighborhood_NPkVill 15717.80937227868\n",
      "Neighborhood_NWAmes -19464.82104501221\n",
      "Neighborhood_NoRidge 20795.472458426415\n",
      "Neighborhood_NridgHt 26365.110652230265\n",
      "Neighborhood_OldTown -14551.780111017304\n",
      "Neighborhood_SWISU -6431.57244566356\n",
      "Neighborhood_Sawyer -9783.546958789526\n",
      "Neighborhood_SawyerW -11657.340138501579\n",
      "Neighborhood_Somerst -6846.704358284622\n",
      "Neighborhood_StoneBr 41203.522828918096\n",
      "Neighborhood_Timber -14855.540380149741\n",
      "Neighborhood_Veenker -1517.9566169933569\n",
      "RoofMatl_ClyTile -478654.25438071834\n",
      "RoofMatl_CompShg 57059.23623264143\n",
      "RoofMatl_Membran 106211.190693858\n",
      "RoofMatl_Metal 66913.72344588468\n",
      "RoofMatl_Roll 36381.53386350284\n",
      "RoofMatl_Tar&Grv 40440.972301878886\n",
      "RoofMatl_WdShake 36208.97899772914\n",
      "RoofMatl_WdShngl 135438.61884522333\n",
      "RoofStyle_Flat -12337.31485735745\n",
      "RoofStyle_Gable -5253.588785290947\n",
      "RoofStyle_Gambrel -11097.160910316225\n",
      "RoofStyle_Hip -2026.0258792707652\n",
      "RoofStyle_Mansard 1876.9790817816684\n",
      "RoofStyle_Shed 28837.111350452764\n",
      "SaleCondition_Abnorml -4024.6283375947887\n",
      "SaleCondition_AdjLand 13749.307511208333\n",
      "SaleCondition_Alloca 7116.425225365338\n",
      "SaleCondition_Family -4914.754668709711\n",
      "SaleCondition_Normal 2327.8017237122704\n",
      "SaleCondition_Partial -14254.151453982771\n",
      "SaleType_COD -6885.89462329635\n",
      "SaleType_CWD -34926.38576524806\n",
      "SaleType_Con 0.0\n",
      "SaleType_ConLD 27363.16924605282\n",
      "SaleType_ConLI 3884.6222541878133\n",
      "SaleType_ConLw -10671.508771934015\n",
      "SaleType_New 27263.37046198627\n",
      "SaleType_Oth -1789.1941969757745\n",
      "SaleType_WD -4238.178604773097\n"
     ]
    }
   ],
   "source": [
    "# Coefficients for each variable in the linear regression\n",
    "for col, coeff in zip(df_train.drop('SalePrice', axis=1).columns, lr.coef_):\n",
    "    print(col, coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.847e+02, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=9.237e+01, with an active set of 40 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 78 iterations, alpha=4.201e+01, previous alpha=4.191e+01, with an active set of 75 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LassoLarsCV testing RMSLE feature engineering: 0.13401176340315712\n",
      "LassoLarsCV testing RMSLE feature engineering: 0.20818137152834748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 146 iterations, i.e. alpha=1.321e+01, with an active set of 136 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:313: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 243 iterations, i.e. alpha=3.437e-02, with an active set of 195 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "/usr/local/lib/python3.6/site-packages/sklearn/linear_model/least_angle.py:339: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 244 iterations, alpha=3.437e-02, previous alpha=3.394e-02, with an active set of 195 regressors.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoLarsCV\n",
    "\n",
    "llcv = LassoLarsCV(max_iter=1000)\n",
    "\n",
    "llcv.fit(x_train, y_train)\n",
    "\n",
    "print('LassoLarsCV testing RMSLE feature engineering: {}'.format(rmsle(y_train,\n",
    "                                                                        np.abs(llcv.predict(x_train)) ) ) ) \n",
    "print('LassoLarsCV testing RMSLE feature engineering: {}'.format(rmsle(y_test,\n",
    "                                                                        np.abs(llcv.predict(x_test)) ) ) ) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "preds = rfr.predict(df_test.drop('SalePrice', axis=1))\n",
    "\n",
    "df_test['SalePrice'] = preds\n",
    "\n",
    "\n",
    "df_test[['Id', 'SalePrice']].to_csv('house_price_predictions.csv', \n",
    "                                    index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest regressor turned out to be the best performining model (also tried elastic net cross validation, huber regression, and multilayer perceptron regressor, but didn't perform well), so its predictions were submitted to Kaggle. According to the testing data, the rfr should have had an RMSLE of about 0.135; however, Kaggle scored the rfr's predictions at 0.153. To put this difference into perspective, consider an RMSLE of 0.135 puts the model at about 1800th place out of 4969 teams while an RMSLE of 0.153 would land at 2675th place.\n",
    "\n",
    "\n",
    "Even stranger was that when the random forest was trained on almost all of train.csv (approximately 99%), the RMSLE improved significantly on Kaggle's public leaderboard: down to 0.144 at 2272nd place!\n",
    "\n",
    "\n",
    "This can indicate a few things, I think. First, this indicates that there is a somewhat meaningful difference between train.csv and test.csv, the latter of which is used to score on the Kaggle leaderboard. Second, this might be a worthwhile lesson: before deployning a machine learning model, train it on the entire data set. Now, tuning the model should still utilize a non-trivial train/test split (70/30, 75/25, 80/20, etc.). Third, the non-trivial test's RMSLE might not be entirely accurate. Fourth, while the RMSLE might not be accurate, it does still seem to be true that if one model is better than another with a 70/30 train/test split, then it will also be better even when there is a 99/01 train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "[CV] C=100000000, epsilon=0.001, gamma=1e-06, kernel=rbf .............\n",
      "[CV]  C=100000000, epsilon=0.001, gamma=1e-06, kernel=rbf, score=0.7588303800361733, total=   0.5s\n",
      "[CV] C=100000000, epsilon=0.001, gamma=1e-06, kernel=rbf .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100000000, epsilon=0.001, gamma=1e-06, kernel=rbf, score=0.8431709572026458, total=   0.4s\n",
      "[CV] C=100000000, epsilon=0.001, gamma=1e-06, kernel=rbf .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    1.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100000000, epsilon=0.001, gamma=1e-06, kernel=rbf, score=0.8788773090918671, total=   0.6s\n",
      "[CV] C=100000000, epsilon=0.001, gamma=1e-05, kernel=rbf .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    2.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100000000, epsilon=0.001, gamma=1e-05, kernel=rbf, score=0.723593623413167, total=   3.7s\n",
      "[CV] C=100000000, epsilon=0.001, gamma=1e-05, kernel=rbf .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    6.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100000000, epsilon=0.001, gamma=1e-05, kernel=rbf, score=0.8349442320275534, total=   2.3s\n",
      "[CV] C=100000000, epsilon=0.001, gamma=1e-05, kernel=rbf .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    8.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100000000, epsilon=0.001, gamma=1e-05, kernel=rbf, score=0.8965182061848442, total=   3.7s\n",
      "[CV] C=100000000, epsilon=0.001, gamma=0.0001, kernel=rbf ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   12.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100000000, epsilon=0.001, gamma=0.0001, kernel=rbf, score=0.6322720819170631, total=   3.9s\n",
      "[CV] C=100000000, epsilon=0.001, gamma=0.0001, kernel=rbf ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   16.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100000000, epsilon=0.001, gamma=0.0001, kernel=rbf, score=0.7248294969105414, total=   4.2s\n",
      "[CV] C=100000000, epsilon=0.001, gamma=0.0001, kernel=rbf ............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   20.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100000000, epsilon=0.001, gamma=0.0001, kernel=rbf, score=0.9044320258877169, total=   4.2s\n",
      "[CV] C=100000000, epsilon=0.001, gamma=0.001, kernel=rbf .............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   25.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  C=100000000, epsilon=0.001, gamma=0.001, kernel=rbf, score=0.8587956979097935, total=   1.3s\n",
      "[CV] C=100000000, epsilon=0.001, gamma=0.001, kernel=rbf .............\n",
      "[CV]  C=100000000, epsilon=0.001, gamma=0.001, kernel=rbf, score=0.7814373041551568, total=   1.3s\n",
      "[CV] C=100000000, epsilon=0.001, gamma=0.001, kernel=rbf .............\n",
      "[CV]  C=100000000, epsilon=0.001, gamma=0.001, kernel=rbf, score=0.8777513151871235, total=   1.2s\n",
      "[CV] C=100000000, epsilon=0.01, gamma=1e-06, kernel=rbf ..............\n",
      "[CV]  C=100000000, epsilon=0.01, gamma=1e-06, kernel=rbf, score=0.7588303330213302, total=   0.4s\n",
      "[CV] C=100000000, epsilon=0.01, gamma=1e-06, kernel=rbf ..............\n",
      "[CV]  C=100000000, epsilon=0.01, gamma=1e-06, kernel=rbf, score=0.8431709823078766, total=   0.4s\n",
      "[CV] C=100000000, epsilon=0.01, gamma=1e-06, kernel=rbf ..............\n",
      "[CV]  C=100000000, epsilon=0.01, gamma=1e-06, kernel=rbf, score=0.8788773247353214, total=   0.5s\n",
      "[CV] C=100000000, epsilon=0.01, gamma=1e-05, kernel=rbf ..............\n",
      "[CV]  C=100000000, epsilon=0.01, gamma=1e-05, kernel=rbf, score=0.7235935917697033, total=   2.6s\n",
      "[CV] C=100000000, epsilon=0.01, gamma=1e-05, kernel=rbf ..............\n",
      "[CV]  C=100000000, epsilon=0.01, gamma=1e-05, kernel=rbf, score=0.8349442190515606, total=   2.1s\n",
      "[CV] C=100000000, epsilon=0.01, gamma=1e-05, kernel=rbf ..............\n",
      "[CV]  C=100000000, epsilon=0.01, gamma=1e-05, kernel=rbf, score=0.8965182011998227, total=   2.5s\n",
      "[CV] C=100000000, epsilon=0.01, gamma=0.0001, kernel=rbf .............\n",
      "[CV]  C=100000000, epsilon=0.01, gamma=0.0001, kernel=rbf, score=0.6322720865663198, total=   3.7s\n",
      "[CV] C=100000000, epsilon=0.01, gamma=0.0001, kernel=rbf .............\n",
      "[CV]  C=100000000, epsilon=0.01, gamma=0.0001, kernel=rbf, score=0.7248294914107688, total=   3.9s\n",
      "[CV] C=100000000, epsilon=0.01, gamma=0.0001, kernel=rbf .............\n",
      "[CV]  C=100000000, epsilon=0.01, gamma=0.0001, kernel=rbf, score=0.9044320197561426, total=   3.9s\n",
      "[CV] C=100000000, epsilon=0.01, gamma=0.001, kernel=rbf ..............\n",
      "[CV]  C=100000000, epsilon=0.01, gamma=0.001, kernel=rbf, score=0.8587957084052215, total=   1.2s\n",
      "[CV] C=100000000, epsilon=0.01, gamma=0.001, kernel=rbf ..............\n",
      "[CV]  C=100000000, epsilon=0.01, gamma=0.001, kernel=rbf, score=0.7814373290636001, total=   1.3s\n",
      "[CV] C=100000000, epsilon=0.01, gamma=0.001, kernel=rbf ..............\n",
      "[CV]  C=100000000, epsilon=0.01, gamma=0.001, kernel=rbf, score=0.8777513298630003, total=   1.2s\n",
      "[CV] C=100000000, epsilon=0.1, gamma=1e-06, kernel=rbf ...............\n",
      "[CV]  C=100000000, epsilon=0.1, gamma=1e-06, kernel=rbf, score=0.7588298429115667, total=   0.4s\n",
      "[CV] C=100000000, epsilon=0.1, gamma=1e-06, kernel=rbf ...............\n",
      "[CV]  C=100000000, epsilon=0.1, gamma=1e-06, kernel=rbf, score=0.8431712320133017, total=   0.4s\n",
      "[CV] C=100000000, epsilon=0.1, gamma=1e-06, kernel=rbf ...............\n",
      "[CV]  C=100000000, epsilon=0.1, gamma=1e-06, kernel=rbf, score=0.8788774829805902, total=   0.5s\n",
      "[CV] C=100000000, epsilon=0.1, gamma=1e-05, kernel=rbf ...............\n",
      "[CV]  C=100000000, epsilon=0.1, gamma=1e-05, kernel=rbf, score=0.723593281966455, total=   3.0s\n",
      "[CV] C=100000000, epsilon=0.1, gamma=1e-05, kernel=rbf ...............\n",
      "[CV]  C=100000000, epsilon=0.1, gamma=1e-05, kernel=rbf, score=0.8349440949143364, total=   2.0s\n",
      "[CV] C=100000000, epsilon=0.1, gamma=1e-05, kernel=rbf ...............\n",
      "[CV]  C=100000000, epsilon=0.1, gamma=1e-05, kernel=rbf, score=0.8965181627307539, total=   3.1s\n",
      "[CV] C=100000000, epsilon=0.1, gamma=0.0001, kernel=rbf ..............\n",
      "[CV]  C=100000000, epsilon=0.1, gamma=0.0001, kernel=rbf, score=0.6322721359528333, total=   3.5s\n",
      "[CV] C=100000000, epsilon=0.1, gamma=0.0001, kernel=rbf ..............\n",
      "[CV]  C=100000000, epsilon=0.1, gamma=0.0001, kernel=rbf, score=0.7248294423978712, total=   3.7s\n",
      "[CV] C=100000000, epsilon=0.1, gamma=0.0001, kernel=rbf ..............\n",
      "[CV]  C=100000000, epsilon=0.1, gamma=0.0001, kernel=rbf, score=0.9044319601704035, total=   3.7s\n",
      "[CV] C=100000000, epsilon=0.1, gamma=0.001, kernel=rbf ...............\n",
      "[CV]  C=100000000, epsilon=0.1, gamma=0.001, kernel=rbf, score=0.8587958132697739, total=   1.1s\n",
      "[CV] C=100000000, epsilon=0.1, gamma=0.001, kernel=rbf ...............\n",
      "[CV]  C=100000000, epsilon=0.1, gamma=0.001, kernel=rbf, score=0.7814375763347948, total=   1.2s\n",
      "[CV] C=100000000, epsilon=0.1, gamma=0.001, kernel=rbf ...............\n",
      "[CV]  C=100000000, epsilon=0.1, gamma=0.001, kernel=rbf, score=0.8777514766012935, total=   1.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  36 out of  36 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [100000000], 'kernel': ['rbf'], 'gamma': [1e-06, 1e-05, 0.0001, 0.001], 'epsilon': [0.001, 0.01, 0.1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Standard scaling increased R^2 from -0.04 to \n",
    "\n",
    "svr_param_dict = {'C': [100000000], # from a previous grid search\n",
    "                  'kernel': ['rbf'],\n",
    "                  'gamma': [10**n for n in range(-6,-2)],\n",
    "                  'epsilon': [10**n for n in range(-3, 0)]}\n",
    "\n",
    "ss = StandardScaler().fit(x_train)\n",
    "gscv = GridSearchCV(estimator=SVR(),\n",
    "                    param_grid=svr_param_dict,\n",
    "                    verbose=10)\n",
    "gscv.fit(ss.transform(x_train), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8393282887352874"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gscv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14715269340583906"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr = gscv.best_estimator_\n",
    "rmsle(y_test, svr.predict(ss.transform(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This support vector regressor is the last model tried here. Although it does not perform as well as the random forest regressor, I did learn a bit about the parameters in a support vector machine.\n",
    "\n",
    "Namely, I never would have thought that 100,000,000 would be a valid value for C, the penalty parameter, yet only near that magnitude is the support vector regressor any good. For smaller C's, like the default of 1.0, there were negative R^2 values, which indicates a fit worse than that of a straight line."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
